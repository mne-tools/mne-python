# Tagging a commit with [circle front] will build the front page and perform test-doc.
# Tagging a commit with [circle full] will build everything.
version: 2
jobs:
    build_docs:
      docker:
        - image: circleci/python:3.7-stretch
      steps:
        - checkout
        - run:
            name: Set BASH_ENV
            command: |
              echo "set -e" >> $BASH_ENV
              echo "export SUBJECTS_DIR=~/mne_data/MNE-sample-data/subjects" >> $BASH_ENV
              echo "export DISPLAY=:99" >> $BASH_ENV
              echo "export OPENBLAS_NUM_THREADS=4" >> $BASH_ENV
              export MNE_ROOT=${PWD}/minimal_cmds
              echo "export MNE_ROOT=${PWD}/minimal_cmds" >> $BASH_ENV
              echo "export MNE_3D_BACKEND=pyvista" >> $BASH_ENV
              echo "export PATH=~/.local/bin/:${MNE_ROOT}/bin:$PATH" >> $BASH_ENV
              curl https://staff.washington.edu/larsoner/minimal_cmds.tar.gz | tar xz
              echo "export LD_LIBRARY_PATH=${MNE_ROOT}/lib:$LD_LIBRARY_PATH" >> $BASH_ENV
              echo "export NEUROMAG2FT_ROOT=${PWD}/minimal_cmds/bin" >> $BASH_ENV
              echo "BASH_ENV:"
              cat $BASH_ENV
        - run:
            name: check neuromag2ft
            command: |
              neuromag2ft --version

        - run:
            name: Merge with upstream
            command: |
              echo $(git log -1 --pretty=%B) | tee gitlog.txt
              echo ${CI_PULL_REQUEST//*pull\//} | tee merge.txt
              if [[ $(cat merge.txt) != "" ]]; then
                echo "Merging $(cat merge.txt)";
                git remote add upstream git://github.com/mne-tools/mne-python.git;
                git pull --ff-only upstream "refs/pull/$(cat merge.txt)/merge";
                git fetch upstream master;
              fi

        # Load our data
        - restore_cache:
            keys:
              - data-cache-0
              - data-cache-1
              - data-cache-2
              - data-cache-3
              - data-cache-4
              - data-cache-5
              - data-cache-6
              - data-cache-7
              - data-cache-8
              - pip-cache

        - run:
            name: Spin up Xvfb
            command: |
              /sbin/start-stop-daemon --start --quiet --pidfile /tmp/custom_xvfb_99.pid --make-pidfile --background --exec /usr/bin/Xvfb -- :99 -screen 0 1400x900x24 -ac +extension GLX +render -noreset;

        # https://github.com/ContinuumIO/anaconda-issues/issues/9190#issuecomment-386508136
        # https://github.com/golemfactory/golem/issues/1019
        - run:
            name: Install PyQt5 dependencies
            command: |
              sudo apt-get install libxkbcommon-x11-0

        - run:
            name: Install graphviz and fonts needed for diagrams
            command: |
              sudo apt-get install graphviz
              mkdir -p $HOME/.fonts
              curl https://codeload.github.com/adobe-fonts/source-code-pro/tar.gz/2.030R-ro/1.050R-it | tar xz -C $HOME/.fonts
              curl https://codeload.github.com/adobe-fonts/source-sans-pro/tar.gz/2.045R-ro/1.095R-it | tar xz -C $HOME/.fonts
              fc-cache -f

        - run:
            name: Get Python running
            command: |
              python -m pip install --user --upgrade --progress-bar off pip numpy vtk setuptools
              python -m pip install --user --upgrade --progress-bar off -r requirements.txt
              python -m pip install --user --upgrade --progress-bar off ipython sphinx_fontawesome sphinx_bootstrap_theme "https://api.github.com/repos/sphinx-gallery/sphinx-gallery/zipball/master" memory_profiler "https://api.github.com/repos/nipy/PySurfer/zipball/master"
              python -m pip install --user -e .

        - save_cache:
            key: pip-cache
            paths:
              - ~/.cache/pip

        # Look at what we have and fail early if there is some library conflict
        - run:
            name: Check installation
            command: |
               which python
               QT_DEBUG_PLUGINS=1 mne sys_info
               LIBGL_DEBUG=verbose python -c "from mayavi import mlab; import matplotlib.pyplot as plt; mlab.figure(); plt.figure()"
               python -c "import mne; mne.set_config('MNE_USE_CUDA', 'false')"  # this is needed for the config tutorial
               python -c "import mne; mne.set_config('MNE_LOGGING_LEVEL', 'info')"
               python -c "import mne; level = mne.get_config('MNE_LOGGING_LEVEL'); assert level.lower() == 'info', repr(level)"

        # Figure out if we should run a full, pattern, or noplot version
        - run:
            name: Get data
            command: |
              python setup.py develop --user
              if ! git remote -v | grep upstream ; then git remote add upstream git://github.com/mne-tools/mne-python.git; fi
              git fetch upstream
              git branch -a
              mkdir -p ~/mne_data
              touch pattern.txt;
              if [ "$CIRCLE_BRANCH" == "master" ] || [[ $(cat gitlog.txt) == *"[circle full]"* ]]; then
                echo html_dev > build.txt;
                python -c "import mne; mne.datasets._download_all_example_data()";
              elif [ "$CIRCLE_BRANCH" == "maint/0.19" ]; then
                echo html_stable > build.txt;
                python -c "import mne; mne.datasets._download_all_example_data()";
              else
                FNAMES=$(git diff --name-only $(git merge-base $CIRCLE_BRANCH upstream/master) $CIRCLE_BRANCH);
                if [[ $(cat gitlog.txt) == *"[circle front]"* ]]; then
                  FNAMES="tutorials/plot_mne_dspm_source_localization.py tutorials/plot_receptive_field.py examples/connectivity/plot_mne_inverse_label_connectivity.py tutorials/plot_sensors_decoding.py tutorials/plot_stats_cluster_spatio_temporal.py tutorials/plot_visualize_evoked.py "${FNAMES};
                  python -c "import mne; print(mne.datasets.testing.data_path(update_path=True))";
                fi;
                echo FNAMES="$FNAMES";
                for FNAME in $FNAMES; do
                  if [[ `expr match $FNAME "\(tutorials\|examples\)/.*plot_.*\.py"` ]] ; then
                    echo "Checking example $FNAME ...";
                    PATTERN=`basename $FNAME`"\\|"$PATTERN;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*sample.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.sample.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*fetch_fsaverage.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.fetch_fsaverage(verbose=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*spm_face.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.spm_face.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*somato.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.somato.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*eegbci.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.eegbci.load_data(1, [3, 6, 10, 14], update_path=True))";
                      python -c "import mne; print(mne.datasets.eegbci.load_data(2, [3], update_path=True))";
                      python -c "import mne; print(mne.datasets.eegbci.load_data(3, [3], update_path=True))";
                      python -c "import mne; print(mne.datasets.eegbci.load_data(4, [3], update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*sleep_physionet.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.sleep_physionet.age.fetch_data([0, 1], recording=[1], update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*hf_sef.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.hf_sef.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*brainstorm.*bst_auditory.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.brainstorm.bst_auditory.data_path(update_path=True))" --accept-brainstorm-license;
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*brainstorm.*bst_resting.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.brainstorm.bst_resting.data_path(update_path=True))" --accept-brainstorm-license;
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*brainstorm.*bst_raw.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.brainstorm.bst_raw.data_path(update_path=True))" --accept-brainstorm-license;
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*brainstorm.*bst_phantom_ctf.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.brainstorm.bst_phantom_ctf.data_path(update_path=True))" --accept-brainstorm-license;
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*brainstorm.*bst_phantom_elekta.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.brainstorm.bst_phantom_elekta.data_path(update_path=True))" --accept-brainstorm-license;
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*hcp_mmp_parcellation.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.sample.data_path(update_path=True))";
                      python -c "import mne; print(mne.datasets.fetch_hcp_mmp_parcellation())" --accept-hcpmmp-license;
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*misc.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.misc.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*testing.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.testing.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*kiloword.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.kiloword.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*mtrf.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.mtrf.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*fieldtrip_cmc.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.fieldtrip_cmc.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*multimodal.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.multimodal.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*fnirs_motor.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.fnirs_motor.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*opm.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.opm.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*phantom_4dbti.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.phantom_4dbti.data_path(update_path=True))";
                    fi;
                    if [[ $(cat $FNAME | grep -x ".*datasets.*limo.*" | wc -l) -gt 0 ]]; then
                      python -c "import mne; print(mne.datasets.limo.data_path(subject=1, update_path=True))";
                    fi;
                  fi;
                done;
                echo PATTERN="$PATTERN";
                if [[ $PATTERN ]]; then
                  PATTERN="\(${PATTERN::-2}\)";
                  echo html_dev-pattern > build.txt;
                else
                  echo html_dev-noplot > build.txt;
                fi;
              fi;
              echo "$PATTERN" > pattern.txt;

        - run:
            name: Verify build type
            command: |
              echo "PATTERN=$(cat pattern.txt)"
              echo "BUILD=$(cat build.txt)"
              ls -al ~/mne_data;

        # Run doctest (if it's full or front) before building the docs
        - run:
            name: make test-doc
            command: |
              if [[ $(cat gitlog.txt) == *"[circle front]"* ]] || [[ $(cat build.txt) == "html_dev" ]] || [[ $(cat build.txt) == "html_stable" ]]; then
                make test-doc;
                mkdir -p doc/_build/test-results/test-doc;
                cp junit-results.xml doc/_build/test-results/test-doc/junit.xml;
              fi;
        # Build docs
        - run:
            name: make html
            command: |
              cd doc;
              PATTERN=$(cat ../pattern.txt) make $(cat ../build.txt);
        - run:
            name: Sanity check system state
            command: |
              python -c "import mne; level = mne.get_config('MNE_LOGGING_LEVEL'); assert level.lower() == 'info', repr(level)"

        # Reduce upload time of artifacts we will (almost) never look at
        - run:
            name: Reduce artifact upload time
            command: |
              if grep -q html_dev-pattern build.txt || grep -q html_dev-noplot build.txt; then
                tar czf doc/_build/html/_downloads.tgz doc/_build/html/_downloads
                rm -Rf doc/_build/html/_downloads
              fi

        # Save the JUnit file
        - store_test_results:
            path: doc/_build/test-results
        - store_artifacts:
            path: doc/_build/test-results
            destination: test-results
        # Save the outputs
        - store_artifacts:
            path: doc/_build/html/
            destination: dev
        - store_artifacts:
            path: doc/_build/html_stable/
            destination: stable
        - persist_to_workspace:
            root: doc/_build
            paths:
              - html
              - html_stable

        # Keep these separate, maybe better in terms of size limitations (?)
        - save_cache:
            key: data-cache-0
            paths:
              - ~/.mne
              - ~/mne_data/mTRF_1.5
        - save_cache:
            key: data-cache-1
            paths:
              - ~/mne_data/HF_SEF
              - ~/mne_data/MEGSIM
        - save_cache:
            key: data-cache-2
            paths:
              - ~/mne_data/MNE-brainstorm-data
              - ~/mne_data/MNE-eegbci-data
        - save_cache:
            key: data-cache-3
            paths:
              - ~/mne_data/MNE-fieldtrip_cmc-data
              - ~/mne_data/MNE-kiloword-data
        - save_cache:
            key: data-cache-4
            paths:
              - ~/mne_data/MNE-misc-data
              - ~/mne_data/MNE-multimodal-data
        - save_cache:
            key: data-cache-5
            paths:
              - ~/mne_data/MNE-OPM-data
              - ~/mne_data/MNE-phantom-4DBTi
        - save_cache:
            key: data-cache-6
            paths:
              - ~/mne_data/MNE-sample-data
              - ~/mne_data/MNE-somato-data
        - save_cache:
            key: data-cache-7
            paths:
              - ~/mne_data/MNE-spm-face
              - ~/mne_data/MNE-testing-ata
        - save_cache:
            key: data-cache-8
            paths:
              - ~/mne_data/MNE-visual_92_categories-data
              - ~/mne_data/MNE-limo-data


    linkcheck:
      # there are a few files excluded from this for expediency, see Makefile
      docker:
        - image: circleci/python:3.6-jessie
      steps:
        - checkout
        - run:
            name: pip install dependencies
            command: |
               set -e;
               python -m pip install --user --progress-bar off numpy scipy matplotlib pillow
               python -m pip install --user --progress-bar off sphinx numpydoc sphinx_fontawesome sphinx_bootstrap_theme "https://api.github.com/repos/sphinx-gallery/sphinx-gallery/zipball/master" memory_profiler
               python -m pip install --user -e .
        - run:
            name: make linkcheck
            command: |
              set -e
              cd doc
              PATH=~/.local/bin:$PATH make linkcheck
        - run:
            name: make linkcheck-grep
            when: always
            command: |
              cd doc
              make linkcheck-grep
        - store_artifacts:
            path: doc/_build/linkcheck
            destination: linkcheck


    deploy:
      docker:
        - image: circleci/python:3.6-jessie
      steps:
        - attach_workspace:
            at: /tmp/build
        - restore_cache:
            keys:
              - website-cache
        - run:
            name: Fetch docs
            command: |
              set -e
              mkdir -p ~/.ssh
              echo -e "Host *\nStrictHostKeyChecking no" > ~/.ssh/config
              chmod og= ~/.ssh/config
              if [ ! -d ~/mne-tools.github.io ]; then
                git clone git@github.com:/mne-tools/mne-tools.github.io.git ~/mne-tools.github.io --depth=1
              fi
        - run:
            name: Deploy docs
            command: |
              set -e;
              if [ "${CIRCLE_BRANCH}" == "master" ] || [ "${CIRCLE_BRANCH}" == "maint/0.19" ]; then
                git config --global user.email "circle@mne.com";
                git config --global user.name "Circle CI";
                cd ~/mne-tools.github.io;
                git checkout master
                git remote -v
                git fetch origin
                git reset --hard origin/master
                git clean -xdf
                if [ "${CIRCLE_BRANCH}" == "master" ]; then
                  echo "Deploying dev docs for ${CIRCLE_BRANCH}.";
                  rm -Rf dev;
                  cp -a /tmp/build/html dev;
                  git add -A;
                  git commit -m "CircleCI update of dev docs (${CIRCLE_BUILD_NUM}).";
                else
                  echo "Deploying stable docs for ${CIRCLE_BRANCH}.";
                  rm -Rf stable;
                  cp -a /tmp/build/html_stable stable;
                  git add -A;
                  git commit -m "CircleCI update of stable docs (${CIRCLE_BUILD_NUM}).";
                fi;
                git push origin master;
              else
                echo "No deployment (build: ${CIRCLE_BRANCH}).";
              fi
        - save_cache:
            key: website-cache
            paths:
              - ~/mne_data/MNE-visual_92_categories-data

workflows:
  version: 2

  default:
    jobs:
      - build_docs
      - deploy:
          requires:
            - build_docs
          filters:
            branches:
              only:
                - master
                - maint/0.19

  weekly:
    jobs:
      - linkcheck
    triggers:
      - schedule:
          # "At 00:00 on Sunday" should be often enough
          cron: "0 0 * * 0"
          filters:
            branches:
              only:
                - master
