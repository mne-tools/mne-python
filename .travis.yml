language: python

# Use container-based infrastructure
sudo: false

env:
    # Enable python 2 and python 3 builds
    # DEPS=full: build optional dependencies: pandas, nitime, statsmodels,
    #            scikit-learn, patsy, nibabel pillow;
    #            in the case of Python 2, also mayavi, traits, pysurfer
    # DEPS=minimal: don't build optional dependencies; tests that require those
    #               dependencies are supposed to be skipped
    #
    # Note that we don't run coverage on Py3k anyway because it slows our tests
    # by a factor of 2 (!), so we make this our "from install dir" run.
    #
    # If we change the old-version run to be a different Python version
    # from 2.6, then we need to update mne.utils.clean_warning_registry.
    #
    # Run one test (3.4) with a non-default stim channel to make sure our
    # tests are explicit about channels.
    #
    # Must force libpng version to avoid silly libpng.so.15 error (MPL 1.1 needs it)
    - PYTHON=2.7 DEPS=full TEST_LOCATION=src
    - PYTHON=2.7 DEPS=nodata TEST_LOCATION=src MNE_DONTWRITE_HOME=true  # also runs flake8
    - PYTHON=3.4 DEPS=full TEST_LOCATION=install MNE_STIM_CHANNEL=STI101
    - PYTHON=2.6 DEPS=full TEST_LOCATION=src NUMPY="=1.7" SCIPY="=0.11" MPL="=1.1" LIBPNG="=1.5" SKLEARN="=0.11" PANDAS="=0.8"
    - PYTHON=2.7 DEPS=minimal TEST_LOCATION=src

# Setup anaconda
before_install:
  - wget -q http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh -O miniconda.sh
  - chmod +x miniconda.sh
  - ./miniconda.sh -b
  - export PATH=/home/travis/miniconda/bin:$PATH
  - conda update --yes --quiet conda
  # We need to create a (fake) display on Travis (allows Mayavi tests to run)
  - export DISPLAY=:99.0
  - /sbin/start-stop-daemon --start --quiet --pidfile /tmp/custom_xvfb_99.pid --make-pidfile --background --exec /usr/bin/Xvfb -- :99 -screen 0 1400x900x24 -ac +extension GLX +render -noreset

install:
    - conda create -n testenv --yes pip python=$PYTHON
    - source activate testenv
    - conda install --yes --quiet numpy$NUMPY scipy$SCIPY nose matplotlib$MPL libpng$LIBPNG
    # We have to replicate e.g. numpy$NUMPY to ensure the recommended (higher) versions
    # are not automatically installed below with multiple "conda install" calls!
    - if [ "${DEPS}" == "full" ]; then
        curl http://lester.ilabs.uw.edu/files/minimal_cmds.tar.gz | tar xz;
        export MNE_ROOT="${PWD}/minimal_cmds";
        export NEUROMAG2FT_ROOT="${PWD}/minimal_cmds/bin";
        source ${MNE_ROOT}/bin/mne_setup_sh;
        conda install --yes --quiet pandas$PANDAS scikit-learn$SKLEARN patsy h5py pillow numpy$NUMPY scipy$SCIPY libpng$LIBPNG matplotlib$MPL;
        pip install -q joblib nibabel;
        if [ "${PYTHON}" == "3.4" ]; then
          conda install --yes --quiet ipython libpng$LIBPNG matplotlib$MPL;
        else
          conda install --yes --quiet ipython==1.1.0 statsmodels numpy$NUMPY scipy$SCIPY pandas$PANDAS libpng$LIBPNG matplotlib$MPL;
          pip install -q nitime;
          if [ "${PYTHON}" == "2.7" ]; then
            conda install --yes --quiet mayavi traits libpng$LIBPNG matplotlib$MPL;
            pip install -q pysurfer faulthandler;
          fi;
        fi;
      fi;
    - if [ "${DEPS}" == "nodata" ]; then
        pip install -q flake8;
      fi;
    - pip install -q coverage coveralls nose-timer
    # check our versions for the major packages
    - NP_VERSION=`python -c 'import numpy; print(numpy.__version__)'`
    - if [ -n "$NUMPY" ] && [ "${NUMPY:(-3)}" != "${NP_VERSION::3}" ]; then
        echo "Incorrect numpy version $NP_VERSION";
        exit 1;
      fi;
    - SP_VERSION=`python -c 'import scipy; print(scipy.__version__)'`
    - if [ -n "$SCIPY" ] && [ "${SCIPY:(-4)}" != "${SP_VERSION::4}" ]; then
        echo "Incorrect scipy version $SP_VERSION";
        exit 1;
      fi;
    - MPL_VERSION=`python -c 'import matplotlib; print(matplotlib.__version__)'`
    - if [ -n "$MPL" ] && [ "${MPL:(-3)}" != "${MPL_VERSION::3}" ]; then
        echo "Incorrect matplotlib version $MPL_VERSION";
        exit 1;
      fi;
    # Suppress the parallel outputs for logging cleanliness
    - export MNE_LOGGING_LEVEL=warning
    - python setup.py build
    - python setup.py install
    - myscripts='browse_raw bti2fiff surf2bem'
    - for script in $myscripts; do mne $script --help; done;
    - SRC_DIR=$(pwd)
    - cd ~
    # Trigger download of testing data. Note that
    # the testing dataset has been constructed to contain the necessary
    # files to act as a FREESURFER_HOME for the coreg tests
    - if [ "${DEPS}" != "nodata" ]; then
        python -c 'import mne; mne.datasets.testing.data_path(verbose=True)';
        if [ "${DEPS}" == "full" ]; then
          export FREESURFER_HOME=$(python -c 'import mne; print(mne.datasets.testing.data_path())');
        fi;
      else
        export MNE_SKIP_TESTING_DATASET_TESTS=true;
      fi;
    - MNE_DIR=$(python -c 'import mne;print(mne.__path__[0])')
    # We run two versions: one out of the source directory (that makes
    # coveralls coverage work), and one out of the install directory (that
    # ensures we have included all necessary files).
    - if [ "${TEST_LOCATION}" == "install" ]; then
        ln -s ${SRC_DIR}/mne/io/tests/data ${MNE_DIR}/io/tests/data;
        ln -s ${SRC_DIR}/mne/io/bti/tests/data ${MNE_DIR}/io/bti/tests/data;
        ln -s ${SRC_DIR}/mne/io/edf/tests/data ${MNE_DIR}/io/edf/tests/data;
        ln -s ${SRC_DIR}/mne/io/kit/tests/data ${MNE_DIR}/io/kit/tests/data;
        ln -s ${SRC_DIR}/mne/io/brainvision/tests/data ${MNE_DIR}/io/brainvision/tests/data;
        ln -s ${SRC_DIR}/mne/io/egi/tests/data ${MNE_DIR}/io/egi/tests/data;
        ln -s ${SRC_DIR}/setup.cfg ${MNE_DIR}/../setup.cfg;
        ln -s ${SRC_DIR}/.coveragerc ${MNE_DIR}/../.coveragerc;
        cd ${MNE_DIR}/../;
      else
        cd ${SRC_DIR};
      fi;
    - if [ "${PYTHON}" != "3.4" ]; then
        COVERAGE=--with-coverage;
      else
        COVERAGE=;
      fi;

script:
    - nosetests -a '!ultra_slow_test' --with-timer --timer-top-n 30 --verbosity=2 $COVERAGE
    - if [ "${DEPS}" == "nodata" ]; then
        make flake;
      fi;

after_success:
    # Need to run from source dir to exectue "git" commands
    # Coverage not collected for 3.4, so don't report it
    - if [ "${TEST_LOCATION}" == "src" ] && [ "${PYTHON}" != "3.4" ]; then
        echo "Running coveralls";
        cd ${SRC_DIR};
        coveralls;
      fi;
